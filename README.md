# K3D Local - Ambiente de Desenvolvimento Kubernetes

> ğŸš€ **Desenvolva Local, Deploy Global**: Ambiente de desenvolvimento local completo usando k3d, PostgreSQL persistente e aplicaÃ§Ãµes automÃ¡ticas. **100% compatÃ­vel com qualquer cluster Kubernetes de produÃ§Ã£o** - AKS, EKS, GKE ou self-managed!

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![k3d](https://img.shields.io/badge/k3d-v5.8.3-blue)](https://k3d.io/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue)](https://www.postgresql.org/)
[![MariaDB](https://img.shields.io/badge/MariaDB-12.0.2-orange)](https://mariadb.org/)
[![Redis](https://img.shields.io/badge/Redis-8.2.3-red)](https://redis.io/)
[![n8n](https://img.shields.io/badge/n8n-1.118.2-orange)](https://n8n.io/)
[![Grafana](https://img.shields.io/badge/Grafana-12.2.1-orange)](https://grafana.com/)
[![Prometheus](https://img.shields.io/badge/Prometheus-v3.7.3-orange)](https://prometheus.io/)
[![GLPI](https://img.shields.io/badge/GLPI-11.0.1-blue)](https://glpi-project.org/)
[![Zabbix](https://img.shields.io/badge/Zabbix-7.4.5-red)](https://www.zabbix.com/)
[![cert-manager](https://img.shields.io/badge/cert--manager-v1.19.0-green)](https://cert-manager.io/)

## ğŸ¯ **Status Atual - Infraestrutura Completa**

- âœ… **k3d Cluster**: 1 server + 2 agents + LoadBalancer com volume bind real
- âœ… **PostgreSQL 16**: PersistÃªncia hostPath + databases para n8n/grafana/prometheus/zabbix
- âœ… **MariaDB 12.0.2**: Banco dedicado GLPI + zabbix_proxy + persistÃªncia hostPath
- âœ… **Redis 8.2.3**: Cache compartilhado com databases separados (DB0-DB4)
- âœ… **n8n 1.118.2**: HTTPS + TLS automÃ¡tico + PostgreSQL + Redis cache + HPA
- âœ… **Grafana 12.2.1**: Dashboards + PostgreSQL + Redis + HPA
- âœ… **Prometheus v3.7.3**: MÃ©tricas + alertas + PostgreSQL + Redis + HPA
- âœ… **GLPI 11.0.1**: Service Desk + MariaDB + Redis + HPA
- âœ… **Zabbix 7.4.5**: Monitoramento completo (9 componentes) + 7 HPAs + PostgreSQL + MariaDB + Redis
- âœ… **cert-manager v1.19.0**: Certificados TLS auto-renovÃ¡veis
- âœ… **Sistema de Backup**: PostgreSQL + MariaDB + PVCs com persistÃªncia real
- âœ… **Namespaces Organizados**: postgres, mariadb, redis, n8n, grafana, prometheus, glpi, zabbix, cert-manager
- âœ… **PermissÃµes Configuradas**: fsGroup correto para todos os componentes
- âœ… **TRUE PaaS BEHAVIOR**: Dados sobrevivem Ã  destruiÃ§Ã£o/recriaÃ§Ã£o do cluster
- âœ… **Scripts de Limpeza**: DestruiÃ§Ã£o completa e segura do ambiente

## ğŸŒ **Pontos de Acesso**

| ServiÃ§o        | URL/Endpoint                                     | Porta | Tipo      |
| -------------- | ------------------------------------------------ | ----- | --------- |
| **n8n**        | `https://n8n.local.127.0.0.1.nip.io:8443`        | 8443  | HTTPS/TLS |
| **Grafana**    | `https://grafana.local.127.0.0.1.nip.io:8443`    | 8443  | HTTPS/TLS |
| **Prometheus** | `https://prometheus.local.127.0.0.1.nip.io:8443` | 8443  | HTTPS/TLS |
| **GLPI**       | `https://glpi.local.127.0.0.1.nip.io:8443`       | 8443  | HTTPS/TLS |
| **Zabbix**     | `https://zabbix.local.127.0.0.1.nip.io:8443`     | 8443  | HTTPS/TLS |
| **PostgreSQL** | `localhost:30432`                                | 30432 | NodePort  |
| **MariaDB**    | `localhost:30306`                                | 30306 | NodePort  |
| **Redis**      | `redis.redis.svc.cluster.local:6379`             | 6379  | ClusterIP |

> âš ï¸ **Porta 8443**: k3d mapeia `443â†’8443` para evitar privilÃ©gios root  
> ğŸŒ **DNS nip.io**: Resolve automaticamente para 127.0.0.1 sem modificar /etc/hosts

## ï¿½ **ConfiguraÃ§Ã£o de PersistÃªncia**

### **âš ï¸ Dados Persistentes vs TemporÃ¡rios**

**ğŸ”´ ConfiguraÃ§Ã£o PadrÃ£o (TemporÃ¡ria):**

- Dados salvos **dentro do cluster** (`/var/lib/rancher/k3s/storage/`)
- **Perdidos** quando cluster Ã© destruÃ­do (`k3d cluster delete`)

**âœ… ConfiguraÃ§Ã£o Recomendada (Persistente):**

- Dados salvos em **`/home/dsm/cluster/`** (hostPath)
- **Sobrevivem** Ã  destruiÃ§Ã£o do cluster

### **ğŸ”§ Como Ativar PersistÃªncia Real**

```bash
# 1. Configurar templates com seu path
./infra/scripts/13.configure-hostpath.sh

# 2. Criar estrutura de diretÃ³rios
./infra/scripts/9.setup-directories.sh

# 3. Deploy com persistÃªncia
./start-all.sh
```

**ğŸ“ Estrutura de dados persistente:**

```
/home/dsm/cluster/
â”œâ”€â”€ postgresql/
â”‚   â”œâ”€â”€ data/                     # PostgreSQL databases (n8n + grafana + prometheus + zabbix)
â”‚   â””â”€â”€ backup/                   # Backups automÃ¡ticos
â”œâ”€â”€ mariadb/                      # MariaDB databases (glpi + zabbix_proxy) - fsGroup: 999
â”œâ”€â”€ redis/                        # Redis cache (compartilhado) - DB0-DB4
â”œâ”€â”€ applications/
â”‚   â”œâ”€â”€ n8n/
â”‚   â”‚   â”œâ”€â”€ data/                # n8n workflows - fsGroup: 1001
â”‚   â”‚   â””â”€â”€ user-data/           # n8n user files
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â”œâ”€â”€ data/                # Grafana dashboards - fsGroup: 472
â”‚   â”‚   â””â”€â”€ plugins-dashboards/  # Grafana plugins
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â”œâ”€â”€ data/                # Prometheus time-series data
â”‚   â”‚   â””â”€â”€ config/              # Prometheus configuraÃ§Ãµes
â”‚   â””â”€â”€ glpi/
â”‚       â”œâ”€â”€ data/                # GLPI dados principais - fsGroup: 1000
â”‚       â”œâ”€â”€ config/              # GLPI configuraÃ§Ãµes
â”‚       â””â”€â”€ files/               # GLPI uploads e anexos
â””â”€â”€ pvc/
    â””â”€â”€ zabbix/                   # Zabbix PVCs persistentes
        â”œâ”€â”€ server/              # Zabbix Server data (5Gi) - fsGroup: 1997
        â”œâ”€â”€ web/                 # Zabbix Web data (2Gi) - fsGroup: 1997
        â”œâ”€â”€ proxy/               # Zabbix Proxy data (1Gi) - fsGroup: 1997
        â””â”€â”€ snmptraps/           # SNMP Traps data (500Mi) - fsGroup: 1997
```

> âš ï¸ **PermissÃµes Importantes**: Cada aplicaÃ§Ã£o possui fsGroup especÃ­fico configurado no deployment para garantir acesso correto aos volumes persistentes.

## ï¿½ğŸ“‹ SumÃ¡rio

- [PrÃ©-requisitos](#-prÃ©-requisitos) âš ï¸ **LEIA PRIMEIRO (Windows/WSL2)**
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [VisÃ£o Geral](#-visÃ£o-geral)
- [Por que k3d?](#-por-que-k3d-pensando-em-produÃ§Ã£o)
- [ConfiguraÃ§Ã£o SSH](#-configuraÃ§Ã£o-ssh-para-github-opcional)
- [InÃ­cio RÃ¡pido](#-inÃ­cio-rÃ¡pido---uso-diÃ¡rio)
- [DocumentaÃ§Ã£o Modular](#-documentaÃ§Ã£o-modular)
- [AplicaÃ§Ãµes DisponÃ­veis](#-aplicaÃ§Ãµes-disponÃ­veis)
- [Scripts DisponÃ­veis](#-scripts-disponÃ­veis)
- [SoluÃ§Ã£o de Problemas](#-soluÃ§Ã£o-de-problemas)
- [Deploy para ProduÃ§Ã£o](#-deploy-para-produÃ§Ã£o)
- [Contribuindo](#-contribuindo-e-fork-do-projeto)

## ğŸ—ï¸ **Arquitetura Dual-Database**

Este projeto implementa uma **arquitetura dual-database** otimizada para diferentes necessidades:

### **ğŸ“Š PostgreSQL 16** (AplicaÃ§Ãµes AvanÃ§adas)

- **N8N**: Workflows complexos, JSON fields, extensÃµes
- **Grafana**: Dashboards, alertas, configuraÃ§Ãµes avanÃ§adas
- **Prometheus**: Time-series data, mÃ©tricas, alertas
- **Zabbix Server**: Monitoramento, histÃ³rico, trends
- **Recursos**: JSONB, arrays, extensÃµes, performance otimizada

### **ğŸ—„ï¸ MariaDB 12.0.2** (AplicaÃ§Ãµes Tradicionais)

- **GLPI**: Compatibilidade oficial MySQL/MariaDB
- **Recursos**: TransaÃ§Ãµes ACID, relaÃ§Ãµes tradicionais, compatibilidade

### **âš¡ Redis 8.2.3** (Cache Compartilhado)

- **Database 0**: N8N cache e sessÃµes
- **Database 1**: Grafana cache
- **Database 2**: GLPI cache e sessÃµes
- **Database 3**: Prometheus cache
- **Database 4**: Zabbix cache (128M dedicado)

> ğŸ’¡ **Vantagem**: Cada aplicaÃ§Ã£o usa o banco ideal para suas necessidades, mantendo performance e compatibilidade mÃ¡ximas.

## ğŸ” **PermissÃµes e SeguranÃ§a**

### **ConfiguraÃ§Ã£o de fsGroup por AplicaÃ§Ã£o**

| AplicaÃ§Ã£o      | fsGroup | ProprietÃ¡rio Pasta          | LocalizaÃ§Ã£o                                  |
| -------------- | ------- | --------------------------- | -------------------------------------------- |
| **PostgreSQL** | 999     | `postgres:postgres`         | `/home/dsm/cluster/postgresql/`              |
| **MariaDB**    | 999     | `systemd-coredump:ssh_keys` | `/home/dsm/cluster/mariadb/`                 |
| **N8N**        | 1001    | `n8n:n8n`                   | `/home/dsm/cluster/applications/n8n/`        |
| **Grafana**    | 472     | `grafana:grafana`           | `/home/dsm/cluster/applications/grafana/`    |
| **Prometheus** | 65534   | `nobody:nogroup`            | `/home/dsm/cluster/applications/prometheus/` |
| **GLPI**       | 1000    | `dsm:dsm`                   | `/home/dsm/cluster/applications/glpi/`       |
| **Zabbix**     | 1997    | `zabbix:zabbix`             | `/home/dsm/cluster/pvc/zabbix/`              |
| **Redis**      | 999     | `redis:redis`               | `/home/dsm/cluster/redis/`                   |

### **ğŸ›¡ï¸ SeguranÃ§a de Credenciais**

- **`.gitignore`**: PadrÃµes configurados para proteger secrets
- **Templates**: Arquivos `.template` para configuraÃ§Ã£o segura
- **Secrets K8s**: Credenciais gerenciadas via Kubernetes secrets
- **Volumes**: PermissÃµes especÃ­ficas por aplicaÃ§Ã£o

> âš ï¸ **IMPORTANTE**: Sempre verifique as permissÃµes das pastas `/home/dsm/cluster/` antes do primeiro deploy!

## ï¿½ PrÃ©-requisitos

### **ğŸ³ Docker Desktop (Windows/WSL2)**

> âš ï¸ **IMPORTANTE**: Se vocÃª estÃ¡ usando Windows com WSL2, Ã© **obrigatÃ³rio** ter o Docker Desktop instalado e rodando!

#### **Windows + WSL2:**

```bash
# 1. Instalar Docker Desktop para Windows
# Download: https://docs.docker.com/desktop/windows/install/

# 2. Verificar se Docker Desktop estÃ¡ rodando
docker version
# Deve mostrar Client e Server version

# 3. Verificar integraÃ§Ã£o WSL2
docker context ls
# Deve mostrar 'default' como atual
```

#### **âŒ Problema Comum:**

```bash
k3d cluster list
# ERRO: Cannot connect to the Docker daemon at unix:///var/run/docker.sock
```

**âœ… SoluÃ§Ã£o:**

1. **Abrir Docker Desktop** no Windows
2. **Aguardar** inicializaÃ§Ã£o completa (Ã­cone azul na system tray)
3. **Verificar** integraÃ§Ã£o WSL2: Settings â†’ Resources â†’ WSL Integration
4. **Habilitar** para sua distribuiÃ§Ã£o WSL2

#### **ğŸ”§ ConfiguraÃ§Ã£o WSL2 Integration:**

- Docker Desktop â†’ Settings â†’ Resources â†’ WSL Integration
- âœ… Enable integration with my default WSL distro
- âœ… Enable integration with additional distros: **Sua distribuiÃ§Ã£o**

### **ğŸ› ï¸ Outros PrÃ©-requisitos:**

- **kubectl**: Cliente Kubernetes
- **k3d**: Kubernetes in Docker
- **git**: Controle de versÃ£o

## ï¿½ğŸš€ InstalaÃ§Ã£o

### **ğŸ“¥ OpÃ§Ã£o 1: Clone via HTTPS (Simples)**

```bash
# Clone o repositÃ³rio via HTTPS
git clone https://github.com/SEU_USUARIO/k3d-local-development.git
cd k3d-local-development
```

### **ğŸ“¥ OpÃ§Ã£o 2: Clone via SSH (Recomendado)**

````bash
```bash
# Clone o repositÃ³rio via SSH (requer configuraÃ§Ã£o SSH)
git clone git@github.com:SEU_USUARIO/k3d-local-development.git
cd k3d-local-development

# OU Clone via HTTPS (pede senha/token)
git clone https://github.com/SEU_USUARIO/k3d-local-development.git
cd k3d-local-development
````

> ğŸ’¡ **SSH Ã© melhor para desenvolvimento**: NÃ£o pede senha, mais seguro. Veja [seÃ§Ã£o SSH](#-configuraÃ§Ã£o-ssh-para-github-opcional) abaixo.
>
> âš ï¸ **IMPORTANTE**: Substitua `SEU_USUARIO` pelo seu usuÃ¡rio real do GitHub!

### **âš™ï¸ ConfiguraÃ§Ã£o Inicial:**

```bash
# 1. Navegue para o diretÃ³rio do projeto (exemplo)
cd /caminho/para/seu/projeto/k3d-local-development

# 2. Liberar execuÃ§Ã£o dos scripts (comando Ãºnico para todos)
find . -name "*.sh" -type f -exec chmod +x {} \;

# 3. Configure as credenciais (OBRIGATÃ“RIO - veja seÃ§Ã£o abaixo)
cp infra/postgres/postgres-secret-admin.yaml.template \
   infra/postgres/postgres-secret-admin.yaml

cp k8s/apps/n8n/n8n-secret-db.yaml.template \
   k8s/apps/n8n/n8n-secret-db.yaml

# 4. Edite os arquivos e substitua YOUR_POSTGRES_ADMIN_PASSWORD_HERE
nano infra/postgres/postgres-secret-admin.yaml
nano k8s/apps/n8n/n8n-secret-db.yaml

# 5. Execute o ambiente completo
./start-all.sh

# OU execute por partes:
# ./infra/scripts/9.start-infra.sh        # Somente infraestrutura
# ./k8s/apps/n8n/scripts/3.start-n8n.sh   # Somente n8n
```

> âš ï¸ **Substitua o caminho**: Use o caminho real onde vocÃª clonou o projeto!

````

> ğŸ’¡ **SSH Ã© melhor para desenvolvimento**: NÃ£o pede senha, mais seguro. Veja [seÃ§Ã£o SSH](#-configuraÃ§Ã£o-ssh-para-github-opcional) abaixo.

### **âš™ï¸ ConfiguraÃ§Ã£o Inicial:**

```bash
# 1. Liberar execuÃ§Ã£o dos scripts (comando Ãºnico para todos)
find . -name "*.sh" -type f -exec chmod +x {} \;

# 2. Configure as credenciais (OBRIGATÃ“RIO - veja seÃ§Ã£o abaixo)
cp infra/postgres/postgres-secret-admin.yaml.template \
   infra/postgres/postgres-secret-admin.yaml

cp k8s/apps/n8n/n8n-secret-db.yaml.template \
   k8s/apps/n8n/n8n-secret-db.yaml

cp k8s/apps/grafana/grafana-secret-db.yaml.template \
   k8s/apps/grafana/grafana-secret-db.yaml

# 3. Edite os arquivos e configure credenciais reais
nano infra/postgres/postgres-secret-admin.yaml     # PostgreSQL admin
nano k8s/apps/n8n/n8n-secret-db.yaml              # n8n database config
nano k8s/apps/grafana/grafana-secret-db.yaml       # Grafana database config

# 4. Execute o ambiente completo
./start-all.sh

# OU execute por partes:
# ./infra/scripts/9.start-infra.sh        # Somente infraestrutura
# ./k8s/apps/n8n/scripts/3.start-n8n.sh   # Somente n8n
````

> **Substitua `SEU_USUARIO`** pelo usuÃ¡rio correto do GitHub!

## ğŸ¯ VisÃ£o Geral

Este projeto configura um ambiente de desenvolvimento local completo usando:

- **k3d**: Cluster Kubernetes local leve
- **PostgreSQL**: Banco de dados persistente
- **n8n**: Plataforma de automaÃ§Ã£o de workflows
- **Traefik**: Ingress controller (padrÃ£o do k3d)
- **cert-manager**: Gerenciamento de certificados TLS self-signed
- **Storage persistente**: PVCs automÃ¡ticos com local-path (padrÃ£o k3d)

## ğŸš€ Por que k3d? Pensando em ProduÃ§Ã£o

### **ğŸ¯ Filosofia: "Desenvolva como Deploy"**

Este projeto usa **k3d** (Kubernetes in Docker) com uma filosofia clara: **criar um ambiente de desenvolvimento que seja o mais prÃ³ximo possÃ­vel da produÃ§Ã£o**.

### **âœ… Vantagens do k3d:**

#### **1. ğŸ­ Compatibilidade Total com ProduÃ§Ã£o**

- **Kubernetes real**: NÃ£o Ã© simulaÃ§Ã£o, Ã© Kubernetes completo
- **APIs idÃªnticas**: Mesmos comandos `kubectl` de produÃ§Ã£o
- **Manifests portÃ¡veis**: YAMLs funcionam em qualquer cluster K8s
- **Ingress real**: Traefik funciona igual ao ambiente produtivo

#### **2. ğŸŒ Path to Production Simplificado**

```mermaid
graph LR
    A[Desenvolvimento k3d] --> B[Teste AKS/EKS/GKE]
    B --> C[Staging K8s]
    C --> D[ProduÃ§Ã£o K8s]

    style A fill:#e1f5fe
    style D fill:#c8e6c9
```

**Mesmos arquivos, ambientes diferentes:**

| Ambiente       | Cluster     | Manifests    | Comandos     |
| -------------- | ----------- | ------------ | ------------ |
| **Local**      | k3d         | âœ… IdÃªnticos | âœ… IdÃªnticos |
| **Cloud**      | AKS/EKS/GKE | âœ… IdÃªnticos | âœ… IdÃªnticos |
| **On-premise** | K8s vanilla | âœ… IdÃªnticos | âœ… IdÃªnticos |

#### **3. ğŸ”„ OpÃ§Ãµes de Deploy em ProduÃ§Ã£o**

**Clusters Gerenciados (Recomendado):**

- **Azure**: AKS (Azure Kubernetes Service)
- **AWS**: EKS (Elastic Kubernetes Service)
- **Google**: GKE (Google Kubernetes Engine)
- **Digital Ocean**: DOKS (DigitalOcean Kubernetes)

**Self-managed:**

- **On-premise**: K8s vanilla + kubeadm
- **Cloud VMs**: K8s em VMs (EC2, Compute Engine, etc.)

**Todos usam os MESMOS manifests YAML!**

#### **4. ğŸ’¡ Facilidade de MigraÃ§Ã£o**

```bash
# ğŸ  Desenvolvimento local (k3d)
kubectl apply -f k8s/apps/n8n/

# ğŸŒ ProduÃ§Ã£o AKS
kubectl apply -f k8s/apps/n8n/

# ğŸš€ ProduÃ§Ã£o EKS
kubectl apply -f k8s/apps/n8n/

# âš¡ ProduÃ§Ã£o GKE
kubectl apply -f k8s/apps/n8n/
```

**Mesmo cÃ³digo, diferentes infraestruturas!**

#### **5. ğŸ§ª ValidaÃ§Ã£o Completa Local**

- **Networking**: Testa ingress, services, DNS interno
- **Storage**: Volumes persistentes funcionam igual produÃ§Ã£o
- **Secrets**: Gerenciamento de credenciais como produÃ§Ã£o
- **Scaling**: HPA e resource limits testÃ¡veis
- **TLS**: Certificados e HTTPS funcionando

### **ğŸ†š ComparaÃ§Ã£o com Alternativas**

| Ferramenta         | Kubernetes Real | Portabilidade | Learning Curve | ProduÃ§Ã£o-Ready |
| ------------------ | --------------- | ------------- | -------------- | -------------- |
| **k3d**            | âœ… 100%         | âœ… Total      | ğŸŸ¡ MÃ©dia       | âœ… Sim         |
| **minikube**       | âœ… 100%         | âœ… Total      | ğŸŸ¡ MÃ©dia       | âœ… Sim         |
| **kind**           | âœ… 100%         | âœ… Total      | ğŸŸ¡ MÃ©dia       | âœ… Sim         |
| **docker-compose** | âŒ NÃ£o          | âŒ Limitada   | ğŸŸ¢ Baixa       | âŒ NÃ£o         |
| **VM local**       | âœ… Depende      | ğŸŸ¡ Parcial    | ğŸ”´ Alta        | ğŸŸ¡ Talvez      |

### **ğŸ“ Aprendizado TransferÃ­vel**

Ao dominar este ambiente, vocÃª aprende:

- **kubectl**: CLI oficial do Kubernetes
- **YAML manifests**: PadrÃ£o da indÃºstria
- **Ingress**: Roteamento HTTP/HTTPS
- **Secrets**: Gerenciamento seguro de credenciais
- **Volumes**: Storage persistente
- **Networking**: Service discovery e DNS

**Conhecimento 100% aplicÃ¡vel em qualquer ambiente Kubernetes!**

## ğŸ›  PrÃ©-requisitos

### Software NecessÃ¡rio

- **Docker Desktop** com WSL2 habilitado
- **kubectl** ([instalaÃ§Ã£o](https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/))
- **k3d** v5.8.3+ ([instalaÃ§Ã£o](https://k3d.io/v5.8.0/#installation))

### Sistema

- **WSL2** com distribuiÃ§Ã£o Linux
- **Storage Class**: local-path (automÃ¡tico k3d - sem configuraÃ§Ã£o manual)

### **ğŸ”“ PermissÃµes de ExecuÃ§Ã£o**

âš ï¸ **IMPORTANTE no Linux/WSL2**: Scripts precisam de permissÃ£o de execuÃ§Ã£o.

```bash
# Comando Ãºnico para liberar TODOS os scripts:
find . -name "*.sh" -type f -exec chmod +x {} \;

# Verificar se funcionou:
ls -la start-all.sh
# Deve mostrar: -rwxr-xr-x ... start-all.sh
```

> ğŸ’¡ **Execute este comando SEMPRE apÃ³s clonar o repositÃ³rio!**

## ğŸ§ ConfiguraÃ§Ã£o WSL2

âš ï¸ **IMPORTANTE**: Configure o WSL2 adequadamente para melhor performance.

ğŸ“– **Guia Completo**: Veja [`README-WSL2.md`](README-WSL2.md) para:

- ConfiguraÃ§Ã£o otimizada do `.wslconfig`
- SugestÃµes de RAM e CPU por hardware
- SoluÃ§Ã£o de problemas de performance
- Monitoramento de recursos

## ğŸ” **IMPORTANTE: ConfiguraÃ§Ã£o de Credenciais**

âš ï¸ **ANTES DE USAR**: Este repositÃ³rio usa templates de seguranÃ§a para proteger senhas.

### **Procedimento ObrigatÃ³rio:**

```bash
# 1. Copiar templates (criar arquivos reais)
cp infra/postgres/postgres-secret-admin.yaml.template \
   infra/postgres/postgres-secret-admin.yaml

cp k8s/apps/n8n/n8n-secret-db.yaml.template \
   k8s/apps/n8n/n8n-secret-db.yaml

# 2. Gerar senha segura
openssl rand -base64 24

# 3. Editar AMBOS arquivos e substituir YOUR_POSTGRES_ADMIN_PASSWORD_HERE
nano infra/postgres/postgres-secret-admin.yaml
nano k8s/apps/n8n/n8n-secret-db.yaml
```

### **âš¡ VerificaÃ§Ã£o AutomÃ¡tica:**

O script `start-all.sh` (ou scripts individuais) verifica automaticamente se as credenciais foram configuradas e exibe instruÃ§Ãµes caso contrÃ¡rio.

ğŸ“– **Detalhes completos**: Veja [`README-SECURITY.md`](README-SECURITY.md)

## ï¿½ DocumentaÃ§Ã£o Modular

Esta documentaÃ§Ã£o estÃ¡ organizada de forma modular para facilitar a manutenÃ§Ã£o e expansÃ£o:

### **ğŸ“– Documentos Principais**

| ğŸ“„ **Documento**                                           | ğŸ¯ **Foco**           | ğŸ“‹ **ConteÃºdo**                                    |
| ---------------------------------------------------------- | --------------------- | -------------------------------------------------- |
| **[README.md](README.md)**                                 | Overview geral        | InstalaÃ§Ã£o, SSH, inÃ­cio rÃ¡pido, visÃ£o geral        |
| **[README-MAIN.md](README-MAIN.md)**                       | DocumentaÃ§Ã£o completa | Guia completo do projeto                           |
| **[README-INFRA.md](README-INFRA.md)**                     | Infraestrutura        | k3d, PostgreSQL, MariaDB, Redis, cert-manager      |
| **[README-N8N.md](README-N8N.md)**                         | AplicaÃ§Ã£o n8n         | Deploy, configuraÃ§Ã£o, workflows, troubleshooting   |
| **[README-GRAFANA.md](README-GRAFANA.md)**                 | AplicaÃ§Ã£o Grafana     | Deploy, dashboards, monitoramento, observabilidade |
| **[README-PROMETHEUS.md](README-PROMETHEUS.md)**           | AplicaÃ§Ã£o Prometheus  | Deploy, mÃ©tricas, alertas, configuraÃ§Ã£o            |
| **[README-GLPI.md](README-GLPI.md)**                       | AplicaÃ§Ã£o GLPI        | Deploy, service desk, ITSM, troubleshooting        |
| **[README-PERSISTENCE.md](README-PERSISTENCE.md)**         | PersistÃªncia de Dados | hostPath volumes, backup, configuraÃ§Ã£o templates   |
| **[README-WSL2.md](README-WSL2.md)**                       | ConfiguraÃ§Ã£o WSL2     | OtimizaÃ§Ã£o, performance, troubleshooting WSL2      |
| **[README-SECURITY.md](README-SECURITY.md)**               | SeguranÃ§a             | Templates, credenciais, boas prÃ¡ticas              |
| **[DAILY-ROUTINE.md](DAILY-ROUTINE.md)**                   | Rotina DiÃ¡ria         | Comandos do dia a dia, manutenÃ§Ã£o                  |
| **[SCRIPT-ANALYSIS-REPORT.md](SCRIPT-ANALYSIS-REPORT.md)** | AnÃ¡lise Scripts       | DocumentaÃ§Ã£o detalhada dos 19 scripts              |

### **ğŸ”„ Quando Usar Cada Documento**

- **ğŸ†• Primeiro uso?** â†’ Comece com este **README.md**
- **ğŸ“š DocumentaÃ§Ã£o completa?** â†’ Consulte **[README-MAIN.md](README-MAIN.md)**
- **ğŸ—ï¸ Problemas de infraestrutura?** â†’ Consulte **[README-INFRA.md](README-INFRA.md)**
- **ğŸ”§ QuestÃµes especÃ­ficas do n8n?** â†’ Veja **[README-N8N.md](README-N8N.md)**
- **ğŸ“Š Monitoramento e Grafana?** â†’ Veja **[README-GRAFANA.md](README-GRAFANA.md)**
- **ï¿½ MÃ©tricas e Prometheus?** â†’ Veja **[README-PROMETHEUS.md](README-PROMETHEUS.md)**
- **ğŸ« Service Desk e GLPI?** â†’ Veja **[README-GLPI.md](README-GLPI.md)**
- **ï¿½ğŸ’¾ Dados nÃ£o persistem apÃ³s destruir cluster?** â†’ Veja **[README-PERSISTENCE.md](README-PERSISTENCE.md)**
- **ğŸ’» ConfiguraÃ§Ã£o WSL2?** â†’ Consulte **[README-WSL2.md](README-WSL2.md)**
- **ğŸ” SeguranÃ§a e credenciais?** â†’ Veja **[README-SECURITY.md](README-SECURITY.md)**
- **ğŸ—“ï¸ Rotina diÃ¡ria de uso?** â†’ Veja **[DAILY-ROUTINE.md](DAILY-ROUTINE.md)**
- **ğŸ” AnÃ¡lise de scripts?** â†’ Veja **[SCRIPT-ANALYSIS-REPORT.md](SCRIPT-ANALYSIS-REPORT.md)**
- **ğŸ“ˆ Expandindo para novas aplicaÃ§Ãµes?** â†’ Use os documentos como template

### **ğŸ’¡ BenefÃ­cios da Estrutura Modular**

- **ğŸ¯ Foco especÃ­fico**: Cada documento trata de um aspecto bem definido
- **ğŸ“š Facilita manutenÃ§Ã£o**: AtualizaÃ§Ãµes em seÃ§Ãµes especÃ­ficas sem conflitos
- **ğŸ”„ Escalabilidade**: FÃ¡cil adicionar novos documentos para novas aplicaÃ§Ãµes
- **ğŸ” Busca rÃ¡pida**: Encontre informaÃ§Ãµes especÃ­ficas sem navegar por documento gigante

## ğŸš€ AplicaÃ§Ãµes DisponÃ­veis

### **ğŸ“¦ AplicaÃ§Ãµes Implementadas**

| ğŸ› ï¸ **AplicaÃ§Ã£o** | ğŸ“ **DescriÃ§Ã£o**           | ğŸŒ **Acesso**                                        | ğŸ”‘ **Login**              | ğŸ“– **DocumentaÃ§Ã£o**                              |
| ---------------- | -------------------------- | ---------------------------------------------------- | ------------------------- | ------------------------------------------------ |
| **n8n**          | AutomaÃ§Ã£o de workflows     | https://n8n.local.127.0.0.1.nip.io:8443              | Setup inicial             | **[README-N8N.md](README-N8N.md)**               |
| **Grafana**      | Monitoramento e dashboards | https://grafana.local.127.0.0.1.nip.io:8443          | admin / admin             | **[README-GRAFANA.md](README-GRAFANA.md)**       |
| **Prometheus**   | MÃ©tricas e alertas         | https://prometheus.local.127.0.0.1.nip.io:8443       | -                         | **[README-PROMETHEUS.md](README-PROMETHEUS.md)** |
| **GLPI**         | Service Desk e ITSM        | https://glpi.local.127.0.0.1.nip.io:8443             | glpi / glpi               | **[README-GLPI.md](README-GLPI.md)**             |
| **Zabbix**       | Monitoramento completo     | https://zabbix.local.127.0.0.1.nip.io:8443           | Admin / zabbix            | **[README-ZABBIX.md](README-ZABBIX.md)**         |
| **Redis**        | Cache & Session Store      | Interno (`redis.redis.svc.cluster.local:6379`)       | -                         | Cache para n8n/grafana/glpi/prometheus/zabbix    |
| **PostgreSQL**   | Banco de dados (Apps)      | Interno (`postgres.postgres.svc.cluster.local:5432`) | postgres / postgres_admin | **[README-INFRA.md](README-INFRA.md)**           |
| **MariaDB**      | Banco de dados (GLPI)      | Interno (`mariadb.mariadb.svc.cluster.local:3306`)   | mariadb_admin / \*\*\*    | Base de dados para GLPI e Zabbix Proxy           |

### **ğŸ”„ Adicionando Novas AplicaÃ§Ãµes**

```bash
# Template para nova aplicaÃ§Ã£o
mkdir -p k8s/apps/NOVA_APP
cp -r k8s/apps/n8n/* k8s/apps/NOVA_APP/
# Editar manifests conforme necessÃ¡rio
# Criar README-NOVA_APP.md baseado no README-N8N.md
```

### **ğŸ“‹ Roadmap de AplicaÃ§Ãµes**

- **âœ… n8n**: AutomaÃ§Ã£o de workflows (implementado)
- **âœ… Grafana**: Dashboards e monitoring (implementado)
- **âœ… Prometheus**: MÃ©tricas e alertas (implementado)
- **âœ… GLPI**: Service Desk e ITSM (implementado)
- **âœ… Zabbix**: Monitoramento completo 7.4.5 (implementado)
- **âœ… Redis**: Cache e sessÃµes (implementado)
- **âœ… PostgreSQL**: Base de dados para apps (implementado)
- **âœ… MariaDB**: Base de dados para GLPI e Zabbix Proxy (implementado)

## ï¿½ğŸ”‘ **ConfiguraÃ§Ã£o SSH para GitHub (Opcional)**

ğŸ§ **Para uso no WSL2**: Configure sua chave SSH dentro do ambiente Linux do WSL2.

ğŸ’¡ **Para clonar e fazer push via SSH** sem digitar senha:

### **1. Gerar Chave SSH (se nÃ£o tiver)**

âš ï¸ **Execute dentro do WSL2** (terminal Linux):

```bash
# Gerar nova chave SSH (substitua seu email)
ssh-keygen -t rsa -b 4096 -C "seu_email@exemplo.com"

# Quando perguntado, salve como (exemplo):
# /home/seu_usuario/.ssh/github_seu_nome

# Adicionar ao agente SSH (necessÃ¡rio no WSL2)
eval "$(ssh-agent -s)"
ssh-add ~/.ssh/github_seu_nome
```

### **2. Adicionar Chave PÃºblica ao GitHub**

```bash
# Copiar chave pÃºblica (no WSL2)
cat ~/.ssh/github_seu_nome.pub

# VÃ¡ em: GitHub â†’ Settings â†’ SSH and GPG Keys â†’ New SSH Key
# Cole o conteÃºdo copiado
```

### **3. Configurar SSH (Recomendado)**

âš ï¸ **Importante para WSL2**: Configurar para usar automaticamente a chave.

```bash
# Criar arquivo ~/.ssh/config (dentro do WSL2)
nano ~/.ssh/config

# Adicionar configuraÃ§Ã£o:
Host github.com
    HostName github.com
    User git
    IdentityFile ~/.ssh/github_seu_nome
    IdentitiesOnly yes

# Definir permissÃµes corretas
chmod 600 ~/.ssh/config
```

### **4. Testar ConexÃ£o**

```bash
# Testar autenticaÃ§Ã£o SSH (dentro do WSL2)
ssh -T git@github.com

# Deve retornar: "Hi SEU_USUARIO! You've successfully authenticated..."
```

### **5. Clonar/Push com SSH**

âš ï¸ **Execute no terminal WSL2**:

```bash
# Clonar via SSH (recomendado) - no WSL2
git clone git@github.com:USUARIO/REPOSITORIO.git

# Ou alterar remote existente para SSH
git remote set-url origin git@github.com:USUARIO/REPOSITORIO.git

# Verificar configuraÃ§Ã£o do git (no WSL2)
git config --global user.name "Seu Nome"
git config --global user.email "seu_email@exemplo.com"
```

ğŸ’¡ **Vantagens do SSH**: NÃ£o precisa digitar senha, mais seguro, suporte a commits automÃ¡ticos.

### **ğŸ”„ PersistÃªncia SSH no WSL2**

âš ï¸ **Importante**: O agente SSH pode parar quando o WSL2 Ã© reiniciado.

**SoluÃ§Ã£o AutomÃ¡tica** - Adicione ao `~/.bashrc` ou `~/.zshrc`:

```bash
# Adicionar ao final do arquivo ~/.bashrc (no WSL2)
echo '
# Auto-start SSH agent and add key
if [ -z "$SSH_AUTH_SOCK" ]; then
    eval "$(ssh-agent -s)" > /dev/null
    ssh-add ~/.ssh/github_seu_nome 2>/dev/null
fi
' >> ~/.bashrc

# Recarregar configuraÃ§Ã£o
source ~/.bashrc
```

**VerificaÃ§Ã£o**:

```bash
# ApÃ³s reiniciar WSL2, testar se ainda funciona
ssh -T git@github.com
```

### VerificaÃ§Ã£o dos PrÃ©-requisitos

âš ï¸ **Execute dentro do WSL2** (nÃ£o no PowerShell/CMD do Windows):

```bash
# Verificar Docker (deve estar integrado ao WSL2)
docker --version

# Verificar kubectl
kubectl version --client

# Verificar k3d
k3d version

# Verificar se Docker estÃ¡ funcionando
docker ps

# Verificar se estÃ¡ no WSL2
uname -a
# Deve mostrar: Linux ... Microsoft ...
```

## ğŸ“ Estrutura do Projeto

```
brioit_local/
â”œâ”€â”€ ğŸ“– README.md                    # Este arquivo (overview geral)
â”œâ”€â”€ ğŸ“– README-MAIN.md               # DocumentaÃ§Ã£o principal completa
â”œâ”€â”€ ğŸ“– README-INFRA.md              # DocumentaÃ§Ã£o de infraestrutura
â”œâ”€â”€ ğŸ“– README-N8N.md                # DocumentaÃ§Ã£o n8n (workflows)
â”œâ”€â”€ ğŸ“– README-GRAFANA.md            # DocumentaÃ§Ã£o Grafana (dashboards)
â”œâ”€â”€ ğŸ“– README-PROMETHEUS.md         # DocumentaÃ§Ã£o Prometheus (mÃ©tricas)
â”œâ”€â”€ ğŸ“– README-GLPI.md               # DocumentaÃ§Ã£o GLPI (service desk)
â”œâ”€â”€ ğŸ“– README-PERSISTENCE.md        # DocumentaÃ§Ã£o de persistÃªncia
â”œâ”€â”€ ğŸ“– README-SECURITY.md           # DocumentaÃ§Ã£o de seguranÃ§a
â”œâ”€â”€ ğŸ“– README-WSL2.md               # DocumentaÃ§Ã£o WSL2
â”œâ”€â”€ ğŸ“– DAILY-ROUTINE.md             # Rotina diÃ¡ria de uso
â”œâ”€â”€ ğŸ“– SCRIPT-ANALYSIS-REPORT.md   # AnÃ¡lise de scripts
â”œâ”€â”€ ğŸš€ start-all.sh                 # Script principal (infraestrutura + aplicaÃ§Ãµes)
â”œâ”€â”€ infra/                          # Infraestrutura base
â”‚   â”œâ”€â”€ k3d/                        # ConfiguraÃ§Ã£o do cluster k3d
â”‚   â”‚   â””â”€â”€ k3d-config.yaml         # Config: 3 nodes, hostPath /home/dsm/cluster
â”‚   â”œâ”€â”€ cert-manager/               # Certificados TLS
â”‚   â”œâ”€â”€ postgres/                   # PostgreSQL (n8n, grafana, prometheus)
â”‚   â”œâ”€â”€ mariadb/                    # MariaDB (GLPI)
â”‚   â”œâ”€â”€ redis/                      # Redis (cache para todas apps)
â”‚   â””â”€â”€ scripts/                    # 19 scripts de infraestrutura
â”‚       â”œâ”€â”€ 1.create-infra.sh      # Cria infraestrutura completa
â”‚       â”œâ”€â”€ 2.destroy-infra.sh     # DestrÃ³i infraestrutura
â”‚       â”œâ”€â”€ 10.start-infra.sh      # Inicia infra (usado pelo start-all.sh)
â”‚       â”œâ”€â”€ 14.clean-cluster-data.sh    # Drop databases (cluster rodando)
â”‚       â”œâ”€â”€ 15.clean-cluster-pvc.sh     # Limpa filesystem (cluster parado)
â”‚       â”œâ”€â”€ 18.destroy-all.sh           # Orquestra destruiÃ§Ã£o completa
â”‚       â””â”€â”€ 19.test-persistence.sh      # Testa persistÃªncia
â”œâ”€â”€ k8s/                           # AplicaÃ§Ãµes Kubernetes
â”‚   â””â”€â”€ apps/
â”‚       â”œâ”€â”€ n8n/                   # n8n (automaÃ§Ã£o de workflows)
â”‚       â”‚   â”œâ”€â”€ manifests/         # YAMLs: deployment, service, ingress, PV/PVC
â”‚       â”‚   â””â”€â”€ scripts/           # Scripts de deploy/destroy
â”‚       â”œâ”€â”€ grafana/               # Grafana (dashboards e monitoring)
â”‚       â”‚   â”œâ”€â”€ manifests/         # YAMLs: deployment, service, ingress, PV/PVC
â”‚       â”‚   â””â”€â”€ scripts/           # Scripts de deploy/destroy
â”‚       â”œâ”€â”€ prometheus/            # Prometheus (mÃ©tricas e alertas)
â”‚       â”‚   â”œâ”€â”€ manifests/         # YAMLs: deployment, service, ingress, PV/PVC
â”‚       â”‚   â””â”€â”€ scripts/           # Scripts de deploy/destroy
â”‚       â””â”€â”€ glpi/                  # GLPI (service desk e ITSM)
â”‚           â”œâ”€â”€ manifests/         # YAMLs: deployment, service, ingress, PV/PVC
â”‚           â””â”€â”€ scripts/           # Scripts de deploy/destroy
â””â”€â”€ backup/                        # Scripts de backup
    â”œâ”€â”€ scripts/                   # Scripts de backup automÃ¡tico
    â””â”€â”€ cronjobs/                  # CronJobs para backups agendados
```

> ğŸ“š **Detalhes completos da estrutura**: Consulte **[README-INFRA.md](README-INFRA.md)** para informaÃ§Ãµes detalhadas sobre cada componente da infraestrutura.

## ğŸš€ InÃ­cio RÃ¡pido - Uso DiÃ¡rio

### **ğŸ“‹ Scripts DisponÃ­veis:**

```bash
# ğŸ¯ OPÃ‡ÃƒO 1: Deploy completo (infraestrutura + aplicaÃ§Ãµes)
./start-all.sh                       # Deploy completo: infra + n8n + grafana
./start-all.sh n8n                   # Deploy infra + somente n8n
./start-all.sh grafana               # Deploy infra + somente grafana

# ğŸ¯ OPÃ‡ÃƒO 2: Deploy manual por componente
./infra/scripts/10.start-infra.sh                # k3d + PostgreSQL + MariaDB + Redis + cert-manager
./k8s/apps/n8n/scripts/3.start-n8n.sh            # Deploy n8n (requer infra)
./k8s/apps/grafana/scripts/3.start-grafana.sh    # Deploy grafana (requer infra)
./k8s/apps/prometheus/scripts/3.start-prometheus.sh  # Deploy prometheus (requer infra)
./k8s/apps/glpi/scripts/3.start-glpi.sh          # Deploy glpi (requer infra)

# ğŸ¯ OPÃ‡ÃƒO 3: Limpeza completa e segura
./infra/scripts/18.destroy-all.sh    # Orquestra: drop DB â†’ destroy cluster â†’ clean filesystem
# OU passo a passo:
./infra/scripts/14.clean-cluster-data.sh  # Drop databases (cluster rodando)
./infra/scripts/2.destroy-infra.sh        # Destroy cluster
./infra/scripts/15.clean-cluster-pvc.sh   # Clean filesystem (cluster parado)

# ğŸ—‘ï¸ OPÃ‡ÃƒO 4: VerificaÃ§Ã£o de status
kubectl get all --all-namespaces       # Ver todos os recursos
kubectl get pods -n n8n                # Status do n8n
kubectl get pods -n grafana            # Status do grafana
kubectl get pods -n prometheus         # Status do prometheus
kubectl get pods -n glpi               # Status do glpi
kubectl get pods -n postgres           # Status do PostgreSQL
kubectl get pods -n mariadb            # Status do MariaDB
kubectl get pods -n redis              # Status do Redis
```

> âš ï¸ **Se aparecer "Permission denied"**: Execute `find . -name "*.sh" -type f -exec chmod +x {} \;` primeiro!

### **ğŸ§  Processo Automatizado:**

| Script                    | O que faz                                                 | Tempo |
| ------------------------- | --------------------------------------------------------- | ----- |
| **start-all.sh**          | Deploy completo: infra + todas apps                       | ~5min |
| **10.start-infra.sh**     | k3d cluster + PostgreSQL + MariaDB + Redis + cert-manager | ~2min |
| **3.start-n8n.sh**        | n8n 1.118.2 + TLS + Redis cache + hosts                   | ~1min |
| **3.start-grafana.sh**    | Grafana 12.2.1 + TLS + PostgreSQL + hosts                 | ~1min |
| **3.start-prometheus.sh** | Prometheus v3.7.3 + TLS + mÃ©tricas + hosts                | ~1min |
| **3.start-glpi.sh**       | GLPI 11.0.1 + MariaDB + Redis + hosts                     | ~1min |
| **18.destroy-all.sh**     | DestruiÃ§Ã£o completa: drop DB â†’ destroy â†’ clean filesystem | ~2min |
| **2.destroy-infra.sh**    | Remove cluster completo (dados preservados em hostPath)   | ~30s  |

### **ğŸ’¡ Fluxo de Uso TÃ­pico:**

```bash
# â˜€ï¸ Primeira execuÃ§Ã£o (deploy completo)
./start-all.sh                       # Infraestrutura + todas aplicaÃ§Ãµes

# ğŸ”„ Deploy aplicaÃ§Ã£o especÃ­fica
./start-all.sh n8n                   # Somente n8n
./start-all.sh grafana               # Somente grafana
./start-all.sh prometheus            # Somente prometheus
./start-all.sh glpi                  # Somente glpi
./start-all.sh zabbix                # Somente zabbix

# ğŸ› ï¸ ManutenÃ§Ã£o (remover aplicaÃ§Ã£o mantendo dados)
./k8s/apps/n8n/scripts/2.destroy-n8n.sh         # Remove n8n (dados preservados)
./k8s/apps/grafana/scripts/2.destroy-grafana.sh # Remove grafana (dados preservados)
./k8s/apps/prometheus/scripts/2.destroy-prometheus.sh # Remove prometheus (dados preservados)
./k8s/apps/glpi/scripts/2.destroy-glpi.sh       # Remove glpi (dados preservados)
./k8s/apps/zabbix/scripts/2.destroy-zabbix.sh   # Remove zabbix (dados preservados)

# ğŸ”„ Reiniciar ambiente (se necessÃ¡rio)
./infra/scripts/2.destroy-infra.sh
./start-all.sh

# ğŸ—‘ï¸ Limpeza COMPLETA (remove tudo incluindo dados)
./infra/scripts/18.destroy-all.sh    # Drop databases â†’ Destroy cluster â†’ Clean filesystem
```

### **ğŸŒ Acesso Ã s AplicaÃ§Ãµes:**

| ServiÃ§o        | URL                                              | Credenciais                              |
| -------------- | ------------------------------------------------ | ---------------------------------------- |
| **n8n**        | `https://n8n.local.127.0.0.1.nip.io:8443`        | Configurar no primeiro acesso            |
| **Grafana**    | `https://grafana.local.127.0.0.1.nip.io:8443`    | admin / admin                            |
| **Prometheus** | `https://prometheus.local.127.0.0.1.nip.io:8443` | Interface de mÃ©tricas                    |
| **GLPI**       | `https://glpi.local.127.0.0.1.nip.io:8443`       | glpi / glpi                              |
| **PostgreSQL** | `localhost:30432`                                | user: `admin`, senha: definida no secret |
| **MariaDB**    | `localhost:30306`                                | user: `mariadb_admin`, senha: no secret  |

### **ï¿½ ConfiguraÃ§Ã£o da Porta 8443**

A porta **8443** Ã© usada porque:

- âœ… **Sem privilÃ©gios root**: Portas < 1024 requerem sudo
- âœ… **k3d mapping**: `443 (cluster) â†’ 8443 (host)`
- âœ… **ConfiguraÃ§Ã£o**: Definida em `/infra/k3d/k3d-config.yaml`

```yaml
# /infra/k3d/k3d-config.yaml
ports:
  - port: 8443:443 # HTTPS: Host:8443 â†’ Cluster:443
```

> **ğŸ’ª Scripts inteligentes: Auto-configuram /etc/hosts e verificam certificados TLS automaticamente!**

### ğŸ“‹ **MÃ©todo Manual (passo a passo):**

#### 1. Setup Completo da Infraestrutura

```bash
# Criar cluster + PostgreSQL + cert-manager
./infra/scripts/1.create-infra.sh
```

#### 2. Deploy do n8n

```bash
# Deploy da aplicaÃ§Ã£o n8n
./k8s/scripts/1.deploy-n8n.sh
```

## ğŸ“… **Fluxo de Trabalho DiÃ¡rio**

### ğŸŒ… **Toda manhÃ£ (ou apÃ³s reiniciar laptop/WSL2):**

```bash
# 1. Abrir WSL e navegar atÃ© o projeto
cd /home/dsm/brioit_local

# 2. Executar script de inicializaÃ§Ã£o (detecta o que precisa fazer)
./start-all.sh

# 3. Aguardar mensagem "Ambiente pronto!" (15s ~ 3min dependendo do estado)

# 4. Abrir browser e acessar:
# https://n8n.local.127.0.0.1.nip.io:8443
```

### â˜• **Durante o dia:**

- **Apenas acessar o browser**: `https://n8n.local.127.0.0.1.nip.io:8443`
- **NÃ£o precisa rodar scripts novamente**

### ğŸ”„ **CenÃ¡rios Comuns:**

```bash
# ğŸŒ… Ligou o computador / Primeira vez
./start-all.sh  # Cria tudo automaticamente

# ğŸ’» Reiniciou WSL2 / Docker Desktop
./start-all.sh  # Detecta e reinicia serviÃ§os

# ğŸ”§ Quer limpar tudo e comeÃ§ar do zero
./infra/scripts/2.destroy-infra.sh  # Remove tudo
./start-all.sh     # Recria do zero

# âœ… Verificar se estÃ¡ funcionando
./start-all.sh  # Mostra status atual
```

## ğŸ”§ **MÃ©todos Alternativos**

### 3. Acessar as AplicaÃ§Ãµes

**ğŸ”’ n8n (HTTPS - Recomendado):**

```bash
# URL principal com TLS
https://n8n.local.127.0.0.1.nip.io:8443
```

**ğŸš€ n8n (Port-forward - Alternativa):**

```bash
# Para desenvolvimento/debug
kubectl port-forward svc/n8n 9090:5678 -n n8n
# Acesso: http://localhost:9090
```

**âš ï¸ ConfiguraÃ§Ã£o necessÃ¡ria:**

```bash
# Adicionar ao /etc/hosts para resolver o domÃ­nio
echo '127.0.0.1 n8n.local.127.0.0.1.nip.io' | sudo tee -a /etc/hosts
```

### 4. Verificar Status

```bash
# Status do cluster
kubectl get nodes

# Status dos pods
kubectl get pods --all-namespaces

# Status dos ingress
kubectl get ingress --all-namespaces
```

## ğŸ— Componentes

### Cluster k3d

- **Nome**: `k3d-cluster`
- **ConfiguraÃ§Ã£o**: 1 server + 2 agents
- **Portas expostas**: 8080:80, 8443:443
- **Storage**: local-path StorageClass (automÃ¡tico k3d)

### PostgreSQL

- **VersÃ£o**: 16
- **Namespace**: default
- **Service**: `postgres.default.svc.cluster.local:5432`
- **Dados persistentes**: PVC automÃ¡tico (gerenciado pelo k3d)
- **Recursos**: 200m CPU, 256Mi RAM

### n8n

- **VersÃ£o**: 1.111.1
- **Namespace**: n8n
- **URL**: https://n8n.local.127.0.0.1.nip.io
- **Banco**: PostgreSQL (configurado via secrets)
- **Recursos**: 100m-500m CPU, 250Mi-1Gi RAM
- **Auto-scaling**: HPA configurado (1-5 replicas)
  - Escala por CPU (70%) e MemÃ³ria (80%)
  - EstabilizaÃ§Ã£o: 60s para scale-up, 300s para scale-down

#### ğŸ”’ Acessando o n8n

**HTTPS (Recomendado - TLS ativo):**

```bash
# URL principal com certificado TLS
https://n8n.local.127.0.0.1.nip.io:8443
```

**âš ï¸ Nota sobre certificados:** Como usamos certificado self-signed, seu browser mostrarÃ¡ um aviso de "conexÃ£o nÃ£o segura". Clique em **"AvanÃ§ado"** â†’ **"Continuar para o site"**.

**Port-forward (Alternativa para desenvolvimento):**

```bash
# Em caso de problemas com ingress/TLS
kubectl port-forward svc/n8n 9090:5678 -n n8n

# Acesso via: http://localhost:9090
```

**ConfiguraÃ§Ã£o do /etc/hosts:**

```bash
# NecessÃ¡rio para resoluÃ§Ã£o do domÃ­nio local
echo '127.0.0.1 n8n.local.127.0.0.1.nip.io' | sudo tee -a /etc/hosts
```

### cert-manager

- **Namespace**: cert-manager
- **Issuer**: self-signed (para desenvolvimento local)
- **Certificados**: Gerados automaticamente para ingress

## ğŸ“œ Scripts DisponÃ­veis

### **ğŸš€ Script Principal (Uso DiÃ¡rio)**

```bash
# ÃšNICO comando necessÃ¡rio para inicializar tudo
./start-all.sh
```

> **Script inteligente**: Detecta automaticamente o estado atual e executa apenas o necessÃ¡rio.

### **ğŸ”§ Scripts EspecÃ­ficos**

### **ğŸ”§ Scripts EspecÃ­ficos**

| **Categoria**                  | **Script**                                          | **FunÃ§Ã£o**                                                                 |
| ------------------------------ | --------------------------------------------------- | -------------------------------------------------------------------------- |
| **ğŸš€ Deploy Completo**         | `start-all.sh`                                      | Infraestrutura + todas aplicaÃ§Ãµes (n8n, grafana, prometheus, glpi, zabbix) |
| **ğŸ—ï¸ Infraestrutura**          | `infra/scripts/10.start-infra.sh`                   | Cluster + PostgreSQL + MariaDB + Redis + cert-manager                      |
| **ğŸ¯ AplicaÃ§Ã£o n8n**           | `k8s/apps/n8n/scripts/3.start-n8n.sh`               | Deploy n8n com HTTPS                                                       |
| **ğŸ“Š AplicaÃ§Ã£o Grafana**       | `k8s/apps/grafana/scripts/3.start-grafana.sh`       | Deploy Grafana com HTTPS                                                   |
| **ï¿½ AplicaÃ§Ã£o Prometheus**     | `k8s/apps/prometheus/scripts/3.start-prometheus.sh` | Deploy Prometheus com HTTPS                                                |
| **ğŸ« AplicaÃ§Ã£o GLPI**          | `k8s/apps/glpi/scripts/3.start-glpi.sh`             | Deploy GLPI com HTTPS                                                      |
| **ï¿½ğŸ—‘ï¸ Limpeza Infra**          | `infra/scripts/2.destroy-infra.sh`                  | Remove cluster (mantÃ©m dados hostPath)                                     |
| **ğŸ§ª Teste PersistÃªncia**      | `infra/scripts/19.test-persistence.sh`              | Testa que dados sobrevivem destroy cluster                                 |
| **ğŸ’¥ DestruiÃ§Ã£o Completa**     | `infra/scripts/18.destroy-all.sh`                   | Remove cluster + databases + filesystem (limpeza total)                    |
| **ğŸ§¹ Limpeza Databases**       | `infra/scripts/14.clean-cluster-data.sh`            | Drop databases PostgreSQL e MariaDB (requer cluster ativo)                 |
| **ğŸ“‚ Limpeza Filesystem**      | `infra/scripts/15.clean-cluster-pvc.sh`             | Remove dados hostPath (requer cluster parado)                              |
| **ğŸ—‘ï¸ Limpeza AplicaÃ§Ãµes**      | `k8s/apps/*/scripts/2.destroy-*.sh`                 | Remove app (mantÃ©m dados)                                                  |
| **ğŸ’¥ Drop Database AplicaÃ§Ã£o** | `k8s/apps/*/scripts/4.drop-database-*.sh`           | Remove PERMANENTEMENTE dados da aplicaÃ§Ã£o                                  |

> ğŸ“š **Lista completa de scripts**: Consulte **[SCRIPT-ANALYSIS-REPORT.md](SCRIPT-ANALYSIS-REPORT.md)** para todos os 19 scripts disponÃ­veis com descriÃ§Ãµes detalhadas e fluxos de trabalho.

## ğŸ”§ SoluÃ§Ã£o de Problemas

### **ï¿½ Problemas Docker Desktop (Windows/WSL2)**

#### Cannot connect to the Docker daemon

```bash
# ERRO comum:
k3d cluster list
# FATA[0000] runtime failed to list nodes: docker failed to get containers
# Cannot connect to the Docker daemon at unix:///var/run/docker.sock

# âœ… SOLUÃ‡ÃƒO:
```

**Passo a passo:**

1. **Abrir Docker Desktop** no Windows
2. **Aguardar** inicializaÃ§Ã£o completa (Ã­cone Docker azul na system tray)
3. **Verificar integraÃ§Ã£o WSL2**:
   - Docker Desktop â†’ Settings â†’ Resources â†’ WSL Integration
   - âœ… Enable integration with my default WSL distro
   - âœ… Enable integration with additional distros
4. **Reiniciar terminal WSL2**
5. **Testar**: `docker version` deve mostrar Client e Server

#### Docker Desktop nÃ£o inicia

```bash
# Verificar se Hyper-V e WSL2 estÃ£o habilitados
wsl --status
# Deve mostrar WSL2 como versÃ£o padrÃ£o

# Se necessÃ¡rio, definir WSL2 como padrÃ£o:
wsl --set-default-version 2
```

#### k3d cluster nÃ£o cria

```bash
# ERRO: k3d cluster create falha
# SOLUÃ‡ÃƒO: Verificar recursos do Docker

# 1. Docker Desktop â†’ Settings â†’ Resources
# 2. Alocar pelo menos:
#    - Memory: 4GB
#    - CPUs: 2
#    - Disk: 20GB
# 3. Apply & Restart Docker Desktop
```

### **ï¿½ğŸš« Problemas de ExecuÃ§Ã£o de Scripts**

#### Permission denied ao executar scripts

```bash
# SoluÃ§Ã£o: Liberar execuÃ§Ã£o de TODOS os scripts
find . -name "*.sh" -type f -exec chmod +x {} \;

# Verificar permissÃµes
ls -la infra/scripts/9.start-n8n.sh
# Deve mostrar: -rwxr-xr-x
```

#### Scripts nÃ£o executam no Windows

```bash
# ERRO: Scripts .sh nÃ£o funcionam no PowerShell/CMD
# SOLUÃ‡ÃƒO: Usar SEMPRE o WSL2

# 1. Abrir WSL2 (Windows Terminal â†’ Ubuntu/Debian)
# 2. Navegar atÃ© o projeto
cd /home/seu_usuario/k3d-local-development
# 3. Executar scripts normalmente
./start-all.sh
```

### **ğŸ”‘ Problemas SSH (GitHub)**

#### Permission denied (publickey)

```bash
# 1. Verificar se a chave estÃ¡ carregada
ssh-add -l

# 2. Se vazio, adicionar chave
eval "$(ssh-agent -s)"
ssh-add ~/.ssh/github_seu_nome

# 3. Testar conexÃ£o
ssh -T git@github.com
```

#### Git ainda pede senha

```bash
# Mudar de HTTPS para SSH
git remote set-url origin git@github.com:USUARIO/REPOSITORIO.git
```

### **ğŸ—ï¸ Problemas de Infraestrutura**

```bash
# Cluster nÃ£o inicia
docker ps                              # Verificar Docker
./infra/scripts/2.destroy-infra.sh     # Destruir cluster
./infra/scripts/10.start-infra.sh      # Recriar cluster

# PostgreSQL nÃ£o conecta
kubectl get pods -n postgres           # Verificar status
kubectl logs postgres-0 -n postgres    # Verificar logs

# MariaDB nÃ£o conecta (GLPI)
kubectl get pods -n mariadb            # Verificar status
kubectl logs mariadb-0 -n mariadb      # Verificar logs

# Redis nÃ£o conecta
kubectl get pods -n redis              # Verificar status
kubectl logs deployment/redis -n redis # Verificar logs

# AplicaÃ§Ãµes nÃ£o carregam
kubectl get pods -n n8n                # n8n status
kubectl get pods -n grafana            # grafana status
kubectl get pods -n prometheus         # prometheus status
kubectl get pods -n glpi               # glpi status

# Ver logs de aplicaÃ§Ã£o especÃ­fica
kubectl logs -f deployment/n8n -n n8n
kubectl logs -f deployment/grafana -n grafana
kubectl logs -f deployment/prometheus -n prometheus
kubectl logs -f deployment/glpi -n glpi
```

### **ğŸ“š Troubleshooting EspecÃ­fico**

Para problemas especÃ­ficos, consulte a documentaÃ§Ã£o modular:

- **ğŸ—ï¸ Infraestrutura (k3d, PostgreSQL, MariaDB, Redis, cert-manager)**: **[README-INFRA.md](README-INFRA.md)**
- **ğŸ¯ AplicaÃ§Ã£o n8n (deployment, acesso, workflows)**: **[README-N8N.md](README-N8N.md)**
- **ğŸ“Š AplicaÃ§Ã£o Grafana (deployment, dashboards, datasources)**: **[README-GRAFANA.md](README-GRAFANA.md)**
- **ğŸ“ˆ AplicaÃ§Ã£o Prometheus (deployment, metrics, alerting)**: **[README-PROMETHEUS.md](README-PROMETHEUS.md)**
- **ğŸ« AplicaÃ§Ã£o GLPI (deployment, helpdesk, inventÃ¡rio)**: **[README-GLPI.md](README-GLPI.md)**
- **ğŸ’¾ PersistÃªncia de dados (hostPath, backup, templates)**: **[README-PERSISTENCE.md](README-PERSISTENCE.md)**
- **ğŸ” SeguranÃ§a (HTTPS, secrets, certificados)**: **[README-SECURITY.md](README-SECURITY.md)**
- **ğŸ“ Rotina DiÃ¡ria (comandos Ãºteis, manutenÃ§Ã£o)**: **[DAILY-ROUTINE.md](DAILY-ROUTINE.md)**

### **ğŸ†˜ Script de DiagnÃ³stico**

```bash
# VerificaÃ§Ã£o completa do ambiente
kubectl get nodes                   # Cluster ativo?
kubectl get pods -A                 # Todos os pods
kubectl get pv,pvc                  # Storage
kubectl get ingress -A              # Networking
kubectl get certificate -A          # TLS
```

### Problemas de Acesso Ã s AplicaÃ§Ãµes

#### ğŸš« "404 page not found"

```bash
# 1. Verificar se o /etc/hosts estÃ¡ configurado
cat /etc/hosts | grep ".nip.io"

# Se nÃ£o aparecer nada, adicionar todas as aplicaÃ§Ãµes:
echo '127.0.0.1 n8n.local.127.0.0.1.nip.io' | sudo tee -a /etc/hosts
echo '127.0.0.1 grafana.local.127.0.0.1.nip.io' | sudo tee -a /etc/hosts
echo '127.0.0.1 prometheus.local.127.0.0.1.nip.io' | sudo tee -a /etc/hosts
echo '127.0.0.1 glpi.local.127.0.0.1.nip.io' | sudo tee -a /etc/hosts

# 2. Usar HTTPS na porta correta
# âŒ Incorreto: http://n8n.local.127.0.0.1.nip.io:8080
# âœ… Correto: https://n8n.local.127.0.0.1.nip.io:8443
```

#### ğŸ”’ "Secure cookie" ou problemas de TLS

```bash
# Problema: AplicaÃ§Ãµes requerem HTTPS mas vocÃª estÃ¡ acessando via HTTP

# SoluÃ§Ã£o 1 - Usar HTTPS (recomendado):
# https://n8n.local.127.0.0.1.nip.io:8443
# https://grafana.local.127.0.0.1.nip.io:8443
# https://prometheus.local.127.0.0.1.nip.io:8443
# https://glpi.local.127.0.0.1.nip.io:8443

# SoluÃ§Ã£o 2 - Port-forward sem TLS (desenvolvimento):
kubectl port-forward svc/n8n 9090:5678 -n n8n
kubectl port-forward svc/grafana 3000:3000 -n grafana
kubectl port-forward svc/prometheus 9090:9090 -n prometheus
kubectl port-forward svc/glpi 8080:80 -n glpi
```

#### ğŸŒ Ingress nÃ£o funciona

```bash
# Verificar ingress de todas as aplicaÃ§Ãµes
kubectl get ingress -A

# Verificar ingress especÃ­fico
kubectl describe ingress n8n -n n8n
kubectl describe ingress grafana -n grafana
kubectl describe ingress prometheus -n prometheus
kubectl describe ingress glpi -n glpi

# Verificar Traefik (LoadBalancer do k3d)
kubectl get pods -n kube-system | grep traefik

# Testar acesso direto ao service (bypass ingress)
kubectl port-forward svc/n8n 9090:5678 -n n8n
kubectl port-forward svc/grafana 3000:3000 -n grafana
kubectl port-forward svc/prometheus 9090:9090 -n prometheus
kubectl port-forward svc/glpi 8080:80 -n glpi
```

### Certificados TLS

```bash
# Verificar cert-manager
kubectl get pods -n cert-manager

# Verificar certificados de todas as aplicaÃ§Ãµes
kubectl get certificates -A

# Verificar certificado especÃ­fico
kubectl describe certificate n8n-tls -n n8n
kubectl describe certificate grafana-tls -n grafana
kubectl describe certificate prometheus-tls -n prometheus
kubectl describe certificate glpi-tls -n glpi

# Recrear certificados (se houver problemas)
kubectl delete certificate n8n-tls -n n8n
kubectl delete certificate grafana-tls -n grafana
kubectl delete certificate prometheus-tls -n prometheus
kubectl delete certificate glpi-tls -n glpi

# Reaplicar manifests de certificados
kubectl apply -f k8s/apps/n8n/k8s/certificate-dns01.yaml
kubectl apply -f k8s/apps/grafana/k8s/certificate-dns01.yaml
kubectl apply -f k8s/apps/prometheus/k8s/certificate-dns01.yaml
kubectl apply -f k8s/apps/glpi/k8s/certificate-dns01.yaml
```

## ğŸ’» Desenvolvimento

### Comandos Ãšteis

```bash
# Listar todos os recursos
kubectl get all -A

# Port-forward para bancos de dados
kubectl port-forward svc/postgres 5432:5432 -n postgres  # PostgreSQL
kubectl port-forward svc/mariadb 3306:3306 -n mariadb    # MariaDB
kubectl port-forward svc/redis 6379:6379 -n redis        # Redis

# Executar comandos nos bancos de dados
kubectl exec -it postgres-0 -n postgres -- psql -U postgres -d n8n
kubectl exec -it postgres-0 -n postgres -- psql -U postgres -d grafana
kubectl exec -it postgres-0 -n postgres -- psql -U postgres -d prometheus
kubectl exec -it mariadb-0 -n mariadb -- mariadb -uroot -p

# Logs em tempo real das aplicaÃ§Ãµes
kubectl logs -f deployment/n8n -n n8n
kubectl logs -f deployment/grafana -n grafana
kubectl logs -f deployment/prometheus -n prometheus
kubectl logs -f deployment/glpi -n glpi

# Verificar recursos do cluster
kubectl top nodes                    # CPU e memÃ³ria dos nodes
kubectl top pods -A                  # CPU e memÃ³ria dos pods
kubectl get events -A --sort-by='.lastTimestamp'  # Eventos recentes

# Escalar aplicaÃ§Ãµes manualmente
kubectl scale deployment/n8n --replicas=2 -n n8n
kubectl scale deployment/grafana --replicas=2 -n grafana
kubectl scale deployment/prometheus --replicas=1 -n prometheus  # Prometheus nÃ£o suporta mÃºltiplas rÃ©plicas
kubectl scale deployment/glpi --replicas=2 -n glpi
```

### Adicionando Novas AplicaÃ§Ãµes

1. Criar namespace: `k8s/apps/nova-app/k8s/nova-app-namespace.yaml`
2. Criar secrets: `k8s/apps/nova-app/k8s/nova-app-secret-*.yaml`
3. Configurar deployment: `k8s/apps/nova-app/k8s/nova-app-deployment.yaml`
4. Criar service: `k8s/apps/nova-app/k8s/nova-app-service.yaml`
5. Configurar ingress: `k8s/apps/nova-app/k8s/nova-app-ingress.yaml`
6. Criar certificado: `k8s/apps/nova-app/k8s/certificate-dns01.yaml`
7. Criar script de deploy: `k8s/apps/nova-app/scripts/3.start-nova-app.sh`
8. Criar script de destroy: `k8s/apps/nova-app/scripts/2.destroy-nova-app.sh`
9. Adicionar ao `start-all.sh` e atualizar documentaÃ§Ã£o

> ğŸ’¡ **Dica**: Use as aplicaÃ§Ãµes existentes (n8n, grafana, prometheus, glpi, zabbix) como template para criar novas aplicaÃ§Ãµes.

### Backup e Restore

```bash
# Backup do PostgreSQL (n8n, grafana, prometheus)
kubectl exec postgres-0 -n postgres -- pg_dump -U postgres n8n > backup-n8n.sql
kubectl exec postgres-0 -n postgres -- pg_dump -U postgres grafana > backup-grafana.sql
kubectl exec postgres-0 -n postgres -- pg_dump -U postgres prometheus > backup-prometheus.sql

# Backup do MariaDB (glpi)
kubectl exec mariadb-0 -n mariadb -- mariadb-dump -uroot -p"${MARIADB_ROOT_PASSWORD}" glpi > backup-glpi.sql

# Restore do PostgreSQL
kubectl exec -i postgres-0 -n postgres -- psql -U postgres n8n < backup-n8n.sql
kubectl exec -i postgres-0 -n postgres -- psql -U postgres grafana < backup-grafana.sql
kubectl exec -i postgres-0 -n postgres -- psql -U postgres prometheus < backup-prometheus.sql

# Restore do MariaDB
kubectl exec -i mariadb-0 -n mariadb -- mariadb -uroot -p"${MARIADB_ROOT_PASSWORD}" glpi < backup-glpi.sql

# Backup completo de volumes (filesystem)
sudo tar -czf backup-cluster-$(date +%Y%m%d).tar.gz /home/dsm/cluster/

# Restore de volumes (com cluster parado)
./infra/scripts/2.destroy-infra.sh
sudo tar -xzf backup-cluster-20241224.tar.gz -C /
./infra/scripts/10.start-infra.sh
```

> ğŸ“š **Detalhes completos**: Consulte **[README-PERSISTENCE.md](README-PERSISTENCE.md)** para estratÃ©gias de backup e restore.

## ğŸš€ Deploy para ProduÃ§Ã£o

### **ğŸ¯ Filosofia: 100% CompatÃ­vel**

Este projeto Ã© projetado para ser **100% compatÃ­vel** com qualquer cluster Kubernetes de produÃ§Ã£o. Os mesmos manifests funcionam em:

- **â˜ï¸ Clusters Gerenciados**: AKS, EKS, GKE
- **ğŸ¢ Self-Managed**: On-premise, VMs Cloud
- **ğŸ  Edge Computing**: k3s, MicroK8s

### **ğŸ“‹ DiferenÃ§as para ProduÃ§Ã£o**

| **Componente**   | **k3d Local**      | **ProduÃ§Ã£o**                  |
| ---------------- | ------------------ | ----------------------------- |
| **Storage**      | `hostPath` (local) | `StorageClass` (cloud disks)  |
| **Certificates** | Self-signed        | Let's Encrypt / Enterprise CA |
| **Ingress**      | Traefik (k3d)      | NGINX/Traefik/Cloud LB        |
| **Scaling**      | 1-3 pods           | HPA com mÃºltiplos nodes       |
| **Monitoring**   | Logs kubectl       | Prometheus/Grafana            |

### **ğŸ”„ MigraÃ§Ã£o Simples**

```bash
# 1. Conectar ao cluster de produÃ§Ã£o
kubectl config use-context production-cluster

# 2. Ajustar apenas configuraÃ§Ãµes especÃ­ficas
# - Storage classes
# - Certificados (Let's Encrypt)
# - Ingress hosts (domÃ­nios reais)

# 3. Deploy com os mesmos manifests
kubectl apply -f infra/
kubectl apply -f k8s/
```

### **ğŸ“š Guias de ProduÃ§Ã£o EspecÃ­ficos**

Para deploy detalhado em produÃ§Ã£o, consulte:

- **ğŸ—ï¸ Infraestrutura de ProduÃ§Ã£o**: **[README-INFRA.md](README-INFRA.md)** - SeÃ§Ã£o "ProduÃ§Ã£o"
- **ğŸ¯ n8n em ProduÃ§Ã£o**: **[README-N8N.md](README-N8N.md)** - SeÃ§Ã£o "Scaling e Performance"
- **ğŸ“Š Grafana em ProduÃ§Ã£o**: **[README-GRAFANA.md](README-GRAFANA.md)** - SeÃ§Ã£o "Monitoramento"
- **ğŸ“ˆ Prometheus em ProduÃ§Ã£o**: **[README-PROMETHEUS.md](README-PROMETHEUS.md)** - SeÃ§Ã£o "High Availability"
- **ğŸ« GLPI em ProduÃ§Ã£o**: **[README-GLPI.md](README-GLPI.md)** - SeÃ§Ã£o "Escalabilidade"

### **âœ… Checklist BÃ¡sico**

- [ ] **Cluster Kubernetes** disponÃ­vel (AKS/EKS/GKE/On-premise)
- [ ] **kubectl** configurado para o cluster
- [ ] **Storage Classes** definidas (para PVC dinÃ¢mico)
- [ ] **DomÃ­nios** configurados (DNS apontando para LoadBalancer)
- [ ] **Certificados** (Let's Encrypt ou Enterprise CA)
- [ ] **Secrets** configurados (senhas, chaves API, tokens)
- [ ] **Monitoring** configurado (Prometheus + Grafana integrados)
- [ ] **Backup** configurado (PostgreSQL, MariaDB, volumes)
- [ ] **High Availability** planejada (mÃºltiplas rÃ©plicas, anti-affinity)

## ğŸ¤ Contribuindo e Fork do Projeto

### **ğŸ´ Como fazer Fork e Contribuir:**

```bash
# 1. Fazer fork no GitHub (clique em "Fork" na pÃ¡gina do projeto)

# 2. Clonar SEU fork (substitua SEU_USUARIO)
git clone git@github.com:SEU_USUARIO/k3d-local-development.git
cd k3d-local-development

# 3. Liberar execuÃ§Ã£o dos scripts
find . -name "*.sh" -type f -exec chmod +x {} \;

# 4. Configurar remote upstream (projeto original)
git remote add upstream git@github.com:USUARIO_ORIGINAL/k3d-local-development.git

# 5. Fazer suas modificaÃ§Ãµes
git checkout -b minha-feature

# 6. Commit e push
git add .
git commit -m "feat: adicionar nova funcionalidade"
git push origin minha-feature

# 7. Abrir Pull Request no GitHub
```

### **ğŸ”„ Mantendo seu Fork Atualizado:**

```bash
# Sincronizar com o projeto original
git fetch upstream
git checkout main
git merge upstream/main
git push origin main
```

### **ğŸ“‹ Checklist para ContribuiÃ§Ãµes:**

- [ ] **Scripts testados**: Todos os scripts executam sem erro
- [ ] **PermissÃµes corretas**: Scripts tÃªm permissÃ£o de execuÃ§Ã£o (`chmod +x`)
- [ ] **DocumentaÃ§Ã£o atualizada**: README.md reflete suas mudanÃ§as
- [ ] **Templates de seguranÃ§a**: Senhas nÃ£o commitadas (usar `.template`)
- [ ] **Compatibility test**: Funciona em WSL2 e distribuiÃ§Ãµes Linux comuns

### **ğŸ’¡ Ideias para ContribuiÃ§Ãµes:**

- **ğŸ†• Novas aplicaÃ§Ãµes**: Service Mesh (Istio/Linkerd), Logging Stack (ELK/Loki), APM (Jaeger)
- **ğŸ”§ Melhorias nos scripts**: DetecÃ§Ã£o automÃ¡tica de estado, logs estruturados, validaÃ§Ãµes
- **ğŸ“š DocumentaÃ§Ã£o**: Guias especÃ­ficos por aplicaÃ§Ã£o, troubleshooting avanÃ§ado, tutoriais
- **ğŸ—ï¸ Infraestrutura**: Backup automÃ¡tico agendado, disaster recovery, multi-cluster
- **ğŸ” SeguranÃ§a**: RBAC completo, network policies, secrets management (Vault), security scanning
- **ğŸ“Š Observabilidade**: Dashboards customizados, alerting rules, distributed tracing
- **ğŸš€ Performance**: OtimizaÃ§Ã£o de recursos, caching strategies, connection pooling

---

**K3D Local Development** - Ambiente Kubernetes com 5 AplicaÃ§Ãµes (n8n, Grafana, Prometheus, GLPI, Zabbix)  
_Ãšltima atualizaÃ§Ã£o: dezembro 2024_
